{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Baselines"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "\n",
    "import scipy.sparse as sparse\n",
    "\n",
    "#Vader\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "#Scikit imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import BernoulliNB"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "seed = 42\n",
    "np.random.seed(seed)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# importing Data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "DATA_FOLDER = 'data/'\n",
    "TWITTER_FOLDER = DATA_FOLDER + 'twitter-datasets/'\n",
    "EN_CORE_WEB_SM = DATA_FOLDER + 'en_core_web_sm-3.0.0'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "pos = pd.read_csv(TWITTER_FOLDER + 'train_pos_full.txt', sep='\\r\\t', header=None, names=['tweet'], engine='python')\n",
    "neg = pd.read_csv(TWITTER_FOLDER + 'train_neg_full.txt', sep='\\r\\t', header=None, names=['tweet'], engine='python', on_bad_lines='skip')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Creating Test/Train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Split test / train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def split_test_train(tweets, test_size=10000):\n",
    "    \"\"\"\n",
    "    Split the labelled tweets in train/test set. Randomisation for the creation is fixed for reproducibility.\n",
    "\n",
    "    :param tweets: Labelled tweets in a Dataframe\n",
    "    :param test_size: The size of the test set\n",
    "    :return: dataset of tweet splited in train/test set\n",
    "    \"\"\"\n",
    "    X = tweets.drop(['is_pos'], axis=1)\n",
    "    Y = tweets.drop(['tweet'],  axis=1)\n",
    "    X, Y = shuffle(X, Y, random_state=42)\n",
    "    X_tr_df, X_te_df, Y_tr_df, Y_te_df = train_test_split(X, Y, test_size=test_size, random_state=42)\n",
    "    return X_tr_df, X_te_df, Y_tr_df, Y_te_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Adding some processing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def combine_pos_neg(pos, neg):\n",
    "    \"\"\"\n",
    "    :param pos: Dataframe containing positive tweets\n",
    "    :param neg: Dataframe containing negative tweets\n",
    "    :return: the combination of the two sets with labels in one Dataframe (without duplicates)\n",
    "    \"\"\"\n",
    "    pos['is_pos'] = 1\n",
    "    neg['is_pos'] = 0\n",
    "    return pd.concat([pos, neg]).drop_duplicates()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def count_parenthesis(tweet):\n",
    "    \"\"\"\n",
    "    :param tweet: a tweet\n",
    "    :return: the count of opening parenthesis minus the closing parenthesis\n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    for c in tweet:\n",
    "        if c == '(':\n",
    "            count += 1\n",
    "        if c == ')':\n",
    "            count -= 1\n",
    "    return count\n",
    "\n",
    "\n",
    "def adding_metadata(tweets):\n",
    "    \"\"\"\n",
    "    Add metadata to the dataframe of tweet : the added metadata are the result of sentiment analysis and the count of parenthesis\n",
    "    :param tweets: A Dataframe of tweet\n",
    "    :return: The same dataframe with additional metadata\n",
    "    \"\"\"\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "    # we keep track on the time to apply the sentiment analysis to the dataset\n",
    "    start_time = time.time()\n",
    "    polarity_scores = tweets['tweet'].apply(analyzer.polarity_scores)\n",
    "    sentiment_analysis_time = time.time() - start_time\n",
    "    print('Time to apply sentiment analysis on the dataset {:.4} seconde'.format(sentiment_analysis_time))\n",
    "\n",
    "    # storing the result of the sentiment analysis\n",
    "    tweets['neg']       = polarity_scores.apply(lambda d : d['neg'])\n",
    "    tweets['neu']       = polarity_scores.apply(lambda d : d['neu'])\n",
    "    tweets['pos']       = polarity_scores.apply(lambda d : d['pos'])\n",
    "    tweets['compound']  = polarity_scores.apply(lambda d : d['compound'])\n",
    "\n",
    "    # storing the parenthesis count\n",
    "    tweets['par_count'] = tweets[\"tweet\"].apply(count_parenthesis)\n",
    "    return tweets"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def scale_data(scaler, X_tr, X_te):\n",
    "    X_tr = scaler.fit_transform(X_tr)\n",
    "    X_te = scaler.transform(X_te)\n",
    "    return X_tr, X_te\n",
    "\n",
    "def get_scaled_data(scaler, X_tr_df, X_te_df, features):\n",
    "    X_tr                     = X_tr_df[features].to_numpy()\n",
    "    X_te                     = X_te_df[features].to_numpy()\n",
    "    X_tr_scaled, X_te_scaled = scale_data(scaler, X_tr, X_te)\n",
    "    return X_tr_scaled, X_te_scaled"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Vectorization"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def vectorize_tweets(vectorizer, X_tr_df, X_te_df):\n",
    "    X_tr_vec = vectorizer.fit_transform(X_tr_df['tweet'])\n",
    "    X_te_vec = vectorizer.transform(X_te_df['tweet'])\n",
    "    return X_tr_vec, X_te_vec"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# PreProcessing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to apply sentiment analysis on the dataset 118.4 seconde\n"
     ]
    }
   ],
   "source": [
    "tweets = combine_pos_neg(pos, neg)\n",
    "tweets = adding_metadata(tweets)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "X_tr_df, X_te_df, Y_tr_df, Y_te_df = split_test_train(tweets, test_size=100000)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "vectorizer = TfidfVectorizer(min_df=5, ngram_range=(1,5), strip_accents='unicode')\n",
    "X_tr_vec,            X_te_vec            = vectorize_tweets(vectorizer, X_tr_df, X_te_df)\n",
    "vectorization_time = time.time() - start_time\n",
    "\n",
    "scaler = StandardScaler()\n",
    "par_count_tr,        par_count_te        = get_scaled_data(scaler, ['par_count'])\n",
    "pol_score_tr,        pol_score_te        = get_scaled_data(scaler, ['neg', 'neu', 'pos', 'compound'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('Time to vectorize the dataset {:.4} seconde'.format(vectorization_time))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Y_tr = np.array(Y_tr_df['is_pos'])\n",
    "Y_te = np.array(Y_te_df['is_pos'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Predictions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "FULL_TRAIN_SET = [True]*len(X_tr_df)\n",
    "FULL_TEST_SET  = [True]*len(X_te_df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def create_inputs(has_vectorized_tweet, has_par_count, has_pol_score):\n",
    "    X_tr = None\n",
    "    X_te = None\n",
    "\n",
    "    if has_par_count:\n",
    "        X_tr = sparse.hstack((X_tr, par_count_tr))\n",
    "        X_te = sparse.hstack((X_te, par_count_te))\n",
    "    if has_pol_score:\n",
    "        X_tr = sparse.hstack((X_tr, pol_score_tr))\n",
    "        X_te = sparse.hstack((X_te, pol_score_te))\n",
    "    if has_vectorized_tweet:\n",
    "        X_tr = sparse.hstack((X_tr, X_tr_vec))\n",
    "        X_te = sparse.hstack((X_te, X_te_vec))\n",
    "\n",
    "    return sparse.csr_matrix(X_tr), sparse.csr_matrix(X_te)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def fit_and_store_res(df_score, model, model_name, has_vectorized_tweet, has_par_count, has_pol_score,\n",
    "                      subset_train=FULL_TRAIN_SET, subset_train_name='Full train set'):\n",
    "    X_tr, X_te = create_inputs(has_vectorized_tweet, has_par_count, has_pol_score)\n",
    "\n",
    "    start_time     = time.time()\n",
    "    model.fit(X_tr[subset_train], Y_tr[subset_train])\n",
    "    time_to_fit     = time.time() - start_time\n",
    "\n",
    "    start_time      = time.time()\n",
    "    test_acc        = model.score(X_te, Y_te)\n",
    "    time_to_predict = time.time() - start_time\n",
    "\n",
    "    new_row = pd.DataFrame()\n",
    "\n",
    "    new_row['model']                         = model_name,\n",
    "    new_row['Train has vectorized tweet']    = has_vectorized_tweet,\n",
    "    new_row['Train has parenthesis count']   = has_par_count,\n",
    "    new_row['Train has polarity score']      = has_pol_score,\n",
    "    new_row['Train on']                      = subset_train_name,\n",
    "    new_row['time to fit [s]']               = time_to_fit,\n",
    "    new_row['time_to_predict [s]']           = time_to_predict,\n",
    "    new_row['accuracy on the training set']  = model.score(X_tr[subset_train], Y_tr[subset_train]),\n",
    "    new_row['accuracy on the full test set'] = test_acc,\n",
    "    new_row['accuracy on subset test 1']     = model.score(X_te[X_te_df.par_count == 0], Y_te[Y_te_df.par_count == 0]),\n",
    "    new_row['accuracy on subset test 2']     = model.score(X_te[X_te_df.par_count >  0], Y_te[Y_te_df.par_count >  0]),\n",
    "    new_row['accuracy on subset test 3']     = model.score(X_te[X_te_df.par_count <  0], Y_te[Y_te_df.par_count <  0])\n",
    "\n",
    "    return pd.concat([df_score, new_row])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Running the predicitons"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression(solver='liblinear')\n",
    "svc     = LinearSVC()\n",
    "rfc     = RandomForestClassifier(max_depth=10, random_state=42)\n",
    "bnb     = BernoulliNB()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_score = pd.DataFrame()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_score = fit_and_store_res(df_score, log_reg, 'Logistic Regression', False, False, True )\n",
    "df_score = fit_and_store_res(df_score, log_reg, 'Logistic Regression', False, True,  False)\n",
    "df_score = fit_and_store_res(df_score, log_reg, 'Logistic Regression', True,  False, False)\n",
    "df_score = fit_and_store_res(df_score, log_reg, 'Logistic Regression', False, True,  True )\n",
    "df_score = fit_and_store_res(df_score, log_reg, 'Logistic Regression', True,  True,  False)\n",
    "df_score = fit_and_store_res(df_score, log_reg, 'Logistic Regression', True,  False, True )\n",
    "df_score = fit_and_store_res(df_score, log_reg, 'Logistic Regression', True,  True,  True )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_score = fit_and_store_res(df_score, log_reg, 'Logistic Regression', True,  True,  True ,\n",
    "                             subset_train = X_tr_df.par_count == 0, subset_train_name= 'Subset 1')\n",
    "df_score = fit_and_store_res(df_score, log_reg, 'Logistic Regression', True,  True,  True ,\n",
    "                             subset_train = X_tr_df.par_count >  0, subset_train_name= 'Subset 2')\n",
    "df_score = fit_and_store_res(df_score, log_reg, 'Logistic Regression', True,  True,  True ,\n",
    "                             subset_train = X_tr_df.par_count <  0, subset_train_name= 'Subset 3')\n",
    "df_score = fit_and_store_res(df_score, log_reg, 'Logistic Regression', True,  True,  True ,\n",
    "                             subset_train = X_tr_df.par_count >= 0, subset_train_name= 'Subset 1 and 2')\n",
    "df_score = fit_and_store_res(df_score, log_reg, 'Logistic Regression', True,  True,  True ,\n",
    "                             subset_train = X_tr_df.par_count <= 0, subset_train_name= 'Subset 1 and 3')\n",
    "df_score = fit_and_store_res(df_score, log_reg, 'Logistic Regression', True,  True,  True ,\n",
    "                             subset_train = X_tr_df.par_count != 0, subset_train_name= 'Subset 2 and 3')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_score = fit_and_store_res(df_score, svc,    'Support Vector Machine', True,  True,  True )\n",
    "df_score = fit_and_store_res(df_score, rfc,    'Random forest',          True,  True,  True )\n",
    "df_score = fit_and_store_res(df_score, bnb,    'Bernoulli',              True,  True,  True )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_score.to_csv(DATA_FOLDER + 'baseline_scores.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_score.to_csv(DATA_FOLDER + 'baseline_scores.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "data": {
      "text/plain": "                    model  Train has vectorized tweet  \\\n0     Logistic Regression                       False   \n0     Logistic Regression                       False   \n0     Logistic Regression                        True   \n0     Logistic Regression                       False   \n0     Logistic Regression                        True   \n0     Logistic Regression                        True   \n0     Logistic Regression                        True   \n0     Logistic Regression                        True   \n0     Logistic Regression                        True   \n0     Logistic Regression                        True   \n0     Logistic Regression                        True   \n0     Logistic Regression                        True   \n0     Logistic Regression                        True   \n0  Support Vector Machine                        True   \n0           Random forest                        True   \n0               Bernoulli                        True   \n\n   Train has parenthesis count  Train has polarity score        Train on  \\\n0                        False                      True  Full train set   \n0                         True                     False  Full train set   \n0                        False                     False  Full train set   \n0                         True                      True  Full train set   \n0                         True                     False  Full train set   \n0                        False                      True  Full train set   \n0                         True                      True  Full train set   \n0                         True                      True        Subset 1   \n0                         True                      True        Subset 2   \n0                         True                      True        Subset 3   \n0                         True                      True  Subset 1 and 2   \n0                         True                      True  Subset 1 and 3   \n0                         True                      True  Subset 2 and 3   \n0                         True                      True  Full train set   \n0                         True                      True  Full train set   \n0                         True                      True  Full train set   \n\n   time to fit [s]  time_to_predict [s]  accuracy on the training set  \\\n0         1.338913             0.002481                      0.644184   \n0         1.110298             0.002080                      0.655340   \n0        35.563274             0.010992                      0.878264   \n0         1.653476             0.003276                      0.738640   \n0        30.441568             0.008271                      0.885723   \n0        51.610270             0.007873                      0.878325   \n0        63.252423             0.010196                      0.885728   \n0        57.304283             0.007033                      0.746165   \n0         8.690293             0.005807                      0.664643   \n0         2.156092             0.006085                      0.524703   \n0        82.040892             0.016990                      0.885138   \n0        62.751840             0.005761                      0.768840   \n0        11.293048             0.006844                      0.765308   \n0       662.595039             0.009373                      0.940806   \n0        42.730294             0.155157                      0.723708   \n0         1.503060             0.044551                      0.819482   \n\n   accuracy on the full test set  accuracy on subset test 1  \\\n0                         0.6413                   0.639107   \n0                         0.6524                   0.577503   \n0                         0.8432                   0.820801   \n0                         0.7378                   0.684000   \n0                         0.8548                   0.826537   \n0                         0.8447                   0.822048   \n0                         0.8565                   0.828657   \n0                         0.7159                   0.829031   \n0                         0.6712                   0.607058   \n0                         0.5193                   0.606934   \n0                         0.8549                   0.827410   \n0                         0.7358                   0.830403   \n0                         0.7725                   0.724529   \n0                         0.8463                   0.817558   \n0                         0.7215                   0.683377   \n0                         0.7969                   0.759446   \n\n   accuracy on subset test 2  accuracy on subset test 3  \n0                   0.664290                   0.570470  \n0                   0.969697                   0.875839  \n0                   0.957813                   0.798658  \n0                   0.969697                   0.875839  \n0                   0.983363                   0.889262  \n0                   0.958408                   0.812081  \n0                   0.983363                   0.889262  \n0                   0.151515                   0.859060  \n0                   0.980986                   0.647651  \n0                   0.036245                   0.889262  \n0                   0.980986                   0.882550  \n0                   0.259655                   0.879195  \n0                   0.980986                   0.885906  \n0                   0.976827                   0.882550  \n0                   0.920974                   0.620805  \n0                   0.959002                   0.889262  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>Train has vectorized tweet</th>\n      <th>Train has parenthesis count</th>\n      <th>Train has polarity score</th>\n      <th>Train on</th>\n      <th>time to fit [s]</th>\n      <th>time_to_predict [s]</th>\n      <th>accuracy on the training set</th>\n      <th>accuracy on the full test set</th>\n      <th>accuracy on subset test 1</th>\n      <th>accuracy on subset test 2</th>\n      <th>accuracy on subset test 3</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Logistic Regression</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>Full train set</td>\n      <td>1.338913</td>\n      <td>0.002481</td>\n      <td>0.644184</td>\n      <td>0.6413</td>\n      <td>0.639107</td>\n      <td>0.664290</td>\n      <td>0.570470</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>Logistic Regression</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>Full train set</td>\n      <td>1.110298</td>\n      <td>0.002080</td>\n      <td>0.655340</td>\n      <td>0.6524</td>\n      <td>0.577503</td>\n      <td>0.969697</td>\n      <td>0.875839</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>Logistic Regression</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>Full train set</td>\n      <td>35.563274</td>\n      <td>0.010992</td>\n      <td>0.878264</td>\n      <td>0.8432</td>\n      <td>0.820801</td>\n      <td>0.957813</td>\n      <td>0.798658</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>Logistic Regression</td>\n      <td>False</td>\n      <td>True</td>\n      <td>True</td>\n      <td>Full train set</td>\n      <td>1.653476</td>\n      <td>0.003276</td>\n      <td>0.738640</td>\n      <td>0.7378</td>\n      <td>0.684000</td>\n      <td>0.969697</td>\n      <td>0.875839</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>Logistic Regression</td>\n      <td>True</td>\n      <td>True</td>\n      <td>False</td>\n      <td>Full train set</td>\n      <td>30.441568</td>\n      <td>0.008271</td>\n      <td>0.885723</td>\n      <td>0.8548</td>\n      <td>0.826537</td>\n      <td>0.983363</td>\n      <td>0.889262</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>Logistic Regression</td>\n      <td>True</td>\n      <td>False</td>\n      <td>True</td>\n      <td>Full train set</td>\n      <td>51.610270</td>\n      <td>0.007873</td>\n      <td>0.878325</td>\n      <td>0.8447</td>\n      <td>0.822048</td>\n      <td>0.958408</td>\n      <td>0.812081</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>Logistic Regression</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>Full train set</td>\n      <td>63.252423</td>\n      <td>0.010196</td>\n      <td>0.885728</td>\n      <td>0.8565</td>\n      <td>0.828657</td>\n      <td>0.983363</td>\n      <td>0.889262</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>Logistic Regression</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>Subset 1</td>\n      <td>57.304283</td>\n      <td>0.007033</td>\n      <td>0.746165</td>\n      <td>0.7159</td>\n      <td>0.829031</td>\n      <td>0.151515</td>\n      <td>0.859060</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>Logistic Regression</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>Subset 2</td>\n      <td>8.690293</td>\n      <td>0.005807</td>\n      <td>0.664643</td>\n      <td>0.6712</td>\n      <td>0.607058</td>\n      <td>0.980986</td>\n      <td>0.647651</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>Logistic Regression</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>Subset 3</td>\n      <td>2.156092</td>\n      <td>0.006085</td>\n      <td>0.524703</td>\n      <td>0.5193</td>\n      <td>0.606934</td>\n      <td>0.036245</td>\n      <td>0.889262</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>Logistic Regression</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>Subset 1 and 2</td>\n      <td>82.040892</td>\n      <td>0.016990</td>\n      <td>0.885138</td>\n      <td>0.8549</td>\n      <td>0.827410</td>\n      <td>0.980986</td>\n      <td>0.882550</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>Logistic Regression</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>Subset 1 and 3</td>\n      <td>62.751840</td>\n      <td>0.005761</td>\n      <td>0.768840</td>\n      <td>0.7358</td>\n      <td>0.830403</td>\n      <td>0.259655</td>\n      <td>0.879195</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>Logistic Regression</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>Subset 2 and 3</td>\n      <td>11.293048</td>\n      <td>0.006844</td>\n      <td>0.765308</td>\n      <td>0.7725</td>\n      <td>0.724529</td>\n      <td>0.980986</td>\n      <td>0.885906</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>Support Vector Machine</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>Full train set</td>\n      <td>662.595039</td>\n      <td>0.009373</td>\n      <td>0.940806</td>\n      <td>0.8463</td>\n      <td>0.817558</td>\n      <td>0.976827</td>\n      <td>0.882550</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>Random forest</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>Full train set</td>\n      <td>42.730294</td>\n      <td>0.155157</td>\n      <td>0.723708</td>\n      <td>0.7215</td>\n      <td>0.683377</td>\n      <td>0.920974</td>\n      <td>0.620805</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>Bernoulli</td>\n      <td>True</td>\n      <td>True</td>\n      <td>True</td>\n      <td>Full train set</td>\n      <td>1.503060</td>\n      <td>0.044551</td>\n      <td>0.819482</td>\n      <td>0.7969</td>\n      <td>0.759446</td>\n      <td>0.959002</td>\n      <td>0.889262</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_score"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
