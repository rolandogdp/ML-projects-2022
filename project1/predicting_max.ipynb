{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import helpers\n",
    "import implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Defining functions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "def accuracy(y, tx, w):\n",
    "    \"\"\"Return the accuracy of the model.\"\"\"\n",
    "    pred    = np.where(tx.dot(w) > 0, 1, 0)\n",
    "    correct = np.sum(pred == y)\n",
    "    return correct / len(y)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The `build_test_train` function split the dataset into training/testing set in oder to perform cross validation tests."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "def build_test_train(y, tx, ratio=0.9, seed=1):\n",
    "    \"\"\"Split the dataset (y, tx) into training/testing set according to the split ratio\"\"\"\n",
    "    # performing permutation before splitting the dataset\n",
    "    np.random.seed(seed)\n",
    "    indices = np.random.permutation(len(y))\n",
    "\n",
    "    # defining indices for y, tx\n",
    "    delimiter_indice = int(ratio * len(y))\n",
    "    te_indices = indices[delimiter_indice:]\n",
    "    tr_indices = indices[:delimiter_indice]\n",
    "\n",
    "    # creating the train/test sets\n",
    "    y_te = y[te_indices]\n",
    "    y_tr = y[tr_indices]\n",
    "    tx_te = tx[te_indices]\n",
    "    tx_tr = tx[tr_indices]\n",
    "    return y_te, y_tr, tx_te, tx_tr"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Loading data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "yb,      input_data,      ids      = helpers.load_csv_data(\"./data/train.csv\")\n",
    "yb_test, input_data_test, ids_test = helpers.load_csv_data(\"./data/test.csv\")\n",
    "# creating classification vector y that fits for logistic regression\n",
    "y  = np.where(yb > 0, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Finding the best model for the classification"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### logistic regression and least squares\n",
    "At first, we have to normalize and format the data."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalization of the data\n",
    "x = implementation.z_normalize(input_data)\n",
    "tx = np.append(np.ones(len(x)).reshape(-1,1), x, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Then, we train our two models."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_log_reg, loss = implementation.logistic_regression(y, tx, initial_w=np.zeros(tx.shape[1]), max_iters=2000, gamma=0.000003)\n",
    "w_ls, loss      = implementation.least_squares(yb, tx)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can see that logistic regression appears to achieve better accuracy."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for logistic regression :  0.75024\n",
      "Accuracy for least squares       :  0.744972\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy for logistic regression : ',accuracy(y, tx, w_log_reg))\n",
    "print('Accuracy for least squares       : ',accuracy(y, tx, w_ls))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Testing overfitting\n",
    "We separate our dataset in the training set and the test set.\n",
    "\n",
    "First, we train the data on the training set and then we test our model on the test set"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "y_te,  y_tr,  tx_te, tx_tr = build_test_train(y, tx)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "w_log_reg, loss = implementation.logistic_regression(y_tr, tx_tr, initial_w=np.zeros(tx_tr.shape[1]), max_iters=2000, gamma=0.000003)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for training set :  0.7504977777777778\n",
      "Accuracy for testing set  :  0.74872\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy for training set : ',accuracy(y_tr, tx_tr, w_log_reg))\n",
    "print('Accuracy for testing set  : ',accuracy(y_te, tx_te, w_log_reg))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can see that the accuracy for the training and testing set is really close.\n",
    "It means that our model does not over fit too much and adding a regulator term would not yield significant improvements on the test set."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "When taking a look at the leaderboard we notice that these results seem not good enough. Maybe our model is too simple as many teams can achieve over 0.8 accuracy."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Using interaction of predictors\n",
    "\n",
    "One good way of augmenting complexity of the model is to add interaction predictors.\n",
    "Let's $p_{ij}$ be the interaction predictor mixing feature $f_i$ and feature $f_j$.\n",
    "Then, $p_{ij} = f_i \\cdot f_j$"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The function `build_interactio_tx` will return an array `tx` with the initial features and the interaction predictors."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "def build_interaction_tx(input_data, normalisation_function):\n",
    "    \"\"\"return the input vector tx with interaction terms\"\"\"\n",
    "    # first normalizing the input data\n",
    "    input_data = normalisation_function(input_data)\n",
    "\n",
    "    n_features = input_data.shape[1]\n",
    "    n_interacted_features = int((n_features-1) * n_features / 2)\n",
    "\n",
    "    # creating the future output array\n",
    "    x = np.empty((n_features + n_interacted_features, len(input_data)))\n",
    "    x[:n_features] = input_data.T\n",
    "\n",
    "    # adding interaction predictors to the output array\n",
    "    index = n_features\n",
    "    for i in range(n_features):\n",
    "        for j in range(i):\n",
    "            x[index] = x[i] * x[j]\n",
    "            index = index + 1\n",
    "\n",
    "    # normalizing the data and adding the bias term\n",
    "    x = normalisation_function(x.T)\n",
    "    tx = np.append(np.ones(len(x)).reshape(-1,1), x, axis=1)\n",
    "\n",
    "    return tx"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "At first, we create interaction our new input with interaction terms.\n",
    "Then, we split in train/test set."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "tx = build_interaction_tx(input_data, implementation.z_normalize)\n",
    "y_te, y_tr, tx_te, tx_tr = build_test_train(y, tx)\n",
    "yb_te, yb_tr, tx_te, tx_tr = build_test_train(yb, tx)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We now train our two models."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "w_log_reg, loss = implementation.logistic_regression(y_tr, tx_tr, initial_w=np.zeros(tx.shape[1]), max_iters=8000, gamma=0.0000005)\n",
    "w_ls,      loss = implementation.least_squares(yb_tr, tx_tr)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Least squares\n",
      "Accuracy for training set :  0.7910755555555555\n",
      "Accuracy for testing set  :  0.7894\n",
      "Logistic regression\n",
      "Accuracy for training set :  0.8161022222222222\n",
      "Accuracy for testing set  :  0.81424\n"
     ]
    }
   ],
   "source": [
    "print('Least squares')\n",
    "print('Accuracy for training set : ',accuracy(y_tr, tx_tr, w_ls))\n",
    "print('Accuracy for testing set  : ',accuracy(y_te, tx_te, w_ls))\n",
    "print('Logistic regression')\n",
    "print('Accuracy for training set : ',accuracy(y_tr, tx_tr, w_log_reg))\n",
    "print('Accuracy for testing set  : ',accuracy(y_te, tx_te, w_log_reg))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can see that Logistic regression achieve slightly better results than the least squares.\n",
    "Moreover, this model is not victim to over fitting as the accuracy for the training set and testing set are really close."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Taining the best model\n",
    "\n",
    "The best model we found is the logistic regression on interaction terms. So we will train this model on the entire dataset."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "tx = build_interaction_tx(input_data, implementation.z_normalize)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "w_best, loss = implementation.logistic_regression(y, tx, initial_w=np.zeros(tx.shape[1]), max_iters=8000, gamma=0.0000005)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now predicting output for the testing set."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "tx_test = build_interaction_tx(input_data_test, implementation.z_normalize)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "y_pred = np.where(tx_test.dot(w_best) > 0, 1, -1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "name = 'submission2'\n",
    "helpers.create_csv_submission(ids_test, y_pred, name)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "ebdaaa5d1fcaf89e6550f8c897f6e669094f4dc7d574cb6a602540667e058bc2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
