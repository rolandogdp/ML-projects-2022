{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import helpers\n",
    "import implementation\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "from matplotlib.ticker import PercentFormatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "def quantile_normalize(data, q=0.75):\n",
    "    low    = (1-q) / 2\n",
    "    high   = 1-low\n",
    "    q_low  = np.quantile(data, low,  axis=0)\n",
    "    q_high = np.quantile(data, high, axis=0)\n",
    "    median = np.quantile(data, 0.5, axis=0)\n",
    "    return (data - median) / (q_high - q_low)\n",
    "\n",
    "def mim_max_normalize(data):\n",
    "    return (data - data.min(axis=0)) / (data.max(axis=0) - data.min(axis=0))\n",
    "\n",
    "def z_normalize(data):\n",
    "    return (data - data.mean(axis=0)) / data.std(axis=0)\n",
    "\n",
    "def accuracy(y, tx, w):\n",
    "    pred    = np.where(tx.dot(w) > 0, 1, 0)\n",
    "    correct = np.sum(np.where(pred == y, 1, 0))\n",
    "    return correct / len(y)\n",
    "\n",
    "def build_test_train(y, tx, proportion=0.9, seed=1):\n",
    "\n",
    "    np.random.seed(seed)\n",
    "    indices = np.random.permutation(len(y))\n",
    "\n",
    "    delimiter_indice = int(proportion * len(y))\n",
    "    te_indices = indices[delimiter_indice:]\n",
    "    tr_indices = indices[:delimiter_indice]\n",
    "    y_te = y[te_indices]\n",
    "    y_tr = y[tr_indices]\n",
    "    tx_te = tx[te_indices]\n",
    "    tx_tr = tx[tr_indices]\n",
    "    return y_te, y_tr, tx_te, tx_tr"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Loading data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "yb, input_data, ids = helpers.load_csv_data(\"./data/train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Finding the best model for the classification"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### logistic regression and least squares\n",
    "At first, we have to normalize and format the data."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalization of the data\n",
    "x = z_normalize(input_data)\n",
    "tx = np.append(np.ones(len(x)).reshape(-1,1), x, axis=1)\n",
    "\n",
    "# creating classification vector y that fits for logistic regression\n",
    "y  = np.where(yb > 0, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Then, we train our two models."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_log_reg, loss = implementation.logistic_regression(y, tx, initial_w=np.zeros(tx.shape[1]), max_iters=2000, gamma=0.000003)\n",
    "w_ls, loss      = implementation.least_squares(yb, tx)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can see that logistic regression appears to achieve better accuracy."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for logistic regression :  0.75024\n",
      "Accuracy for least squares       :  0.744972\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy for logistic regression : ',accuracy(y, tx, w_log_reg))\n",
    "print('Accuracy for least squares       : ',accuracy(y, tx, w_ls))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Testing overfitting\n",
    "We separate our dataset in the training set and the test set.\n",
    "\n",
    "First, we train the data on the training set and then we test our model on the test set"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "y_te,  y_tr,  tx_te, tx_tr = build_test_train(y, tx)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "w_log_reg, loss = implementation.logistic_regression(y_tr, tx_tr, initial_w=np.zeros(tx_tr.shape[1]), max_iters=2000, gamma=0.000003)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for training set :  0.7504977777777778\n",
      "Accuracy for testing set  :  0.74872\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy for training set : ',accuracy(y_tr, tx_tr, w_log_reg))\n",
    "print('Accuracy for testing set  : ',accuracy(y_te, tx_te, w_log_reg))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can see that the accuracy for the training and testing set is really close.\n",
    "It means that our model does not over fit too much and adding a regulator term would not yield significant improvements on the test set."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "When taking a look at the leaderboard we notice that these results seem not good enough. Maybe our model is too simple as many teams can achieve over 0.8 accuracy."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Using interaction of predictors"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "def build_interaction_tx(input_data, normalisation_function):\n",
    "    input_data = normalisation_function(input_data)\n",
    "\n",
    "    n_features = input_data.shape[1]\n",
    "    n_interacted_features = int(n_features + (n_features-1) * n_features / 2)\n",
    "\n",
    "    x = np.empty((n_interacted_features, len(input_data)))\n",
    "    x[:n_features] = input_data.T\n",
    "    index = n_features\n",
    "    for i in range(n_features):\n",
    "        for j in range(i):\n",
    "            x[index] = x[i] * x[j]\n",
    "            index = index + 1\n",
    "\n",
    "    x = normalisation_function(x.T)\n",
    "    tx = np.append(np.ones(len(x)).reshape(-1,1), x, axis=1)\n",
    "\n",
    "    return tx"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [],
   "source": [
    "tx = build_interaction_tx(input_data, z_normalize)\n",
    "y_te, y_tr, tx_te, tx_tr = build_test_train(y, tx)\n",
    "yb_te, yb_tr, tx_te, tx_tr = build_test_train(yb, tx)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [],
   "source": [
    "w_ls, loss_tr = implementation.least_squares(yb_tr, tx_tr)\n",
    "accuracy_te_ls = accuracy(y_te, tx_te, w_ls)\n",
    "accuracy_tr_ls = accuracy(y_tr, tx_tr, w_ls)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6577288888888889        0.65376\n",
      "0.8006222222222222        0.7992\n",
      "0.8077955555555556        0.80568\n",
      "0.8105955555555555        0.80876\n",
      "0.8121733333333333        0.80996\n",
      "0.8132222222222222        0.8104\n",
      "0.8139155555555555        0.8108\n",
      "0.8144533333333334        0.81144\n",
      "0.8147244444444445        0.81236\n",
      "0.8150222222222222        0.81264\n",
      "0.8152622222222222        0.813\n",
      "0.8153777777777778        0.8136\n",
      "0.8156533333333333        0.8138\n",
      "0.81584                   0.81408\n",
      "0.8158888888888889        0.814\n",
      "0.8159466666666667        0.81412\n",
      "0.8161022222222222        0.81424\n",
      "0.8161777777777778        0.8142\n",
      "0.8161688888888889        0.81432\n",
      "0.8161155555555556        0.8142\n"
     ]
    }
   ],
   "source": [
    "initial_w = np.zeros(tx.shape[1])\n",
    "max_iters = 70000\n",
    "gamma     = 0.0000005\n",
    "w_log_reg, loss   = implementation.logistic_regression(y_tr, tx_tr, initial_w, max_iters, gamma)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.81424\n"
     ]
    }
   ],
   "source": [
    "accuracy_te = accuracy(y_te, tx_te, w_log_reg)\n",
    "accuracy_tr = accuracy(y_tr, tx_tr, w_log_reg)\n",
    "\n",
    "print(accuracy_te)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Trash"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "outputs": [],
   "source": [
    "def GD(y, tx, initial_w, max_iters, gamma, gradient_func, loss_func):\n",
    "    w = initial_w\n",
    "\n",
    "    for i in range(max_iters):\n",
    "        if i%500 == 0:\n",
    "            print(str(accuracy(y, tx, w)).ljust(25, ' '), accuracy(y_te, tx_te, w))\n",
    "        grad = gradient_func(y, tx, w)\n",
    "        w = w - gamma * grad\n",
    "\n",
    "    loss = loss_func(y, tx, w)\n",
    "    return w, loss\n",
    "\n",
    "def logistic_regression(y, tx, initial_w, max_iters, gamma):\n",
    "    w, loss = GD(y, tx, initial_w, max_iters, gamma, implementation.logistic_gradient, implementation.logistic_loss)\n",
    "    return w, loss"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "ebdaaa5d1fcaf89e6550f8c897f6e669094f4dc7d574cb6a602540667e058bc2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
